{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Infection_Detection_SVM.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "p4JBCoaARlth"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_u9U5GsRKKnO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "import pandas as pd\n",
        "pd.options.display.max_rows = 20\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "bg = pd.read_excel('/content/drive/My Drive/EEC 193/EEC 193B/Burn_Glucose_022020.xlsx', skiprows = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekWDiq0hvtyF",
        "colab_type": "code",
        "outputId": "09206975-4a09-4687-f9e1-bab230db58af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXcQ0KMM_hzw",
        "colab_type": "code",
        "outputId": "6fe1603d-7592-45a9-a318-0208c2ae308a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        }
      },
      "source": [
        "bg"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PER_CODE</th>\n",
              "      <th>Collection Date</th>\n",
              "      <th>Time Vitals</th>\n",
              "      <th>Systolic</th>\n",
              "      <th>Diastolic</th>\n",
              "      <th>MAP</th>\n",
              "      <th>HR</th>\n",
              "      <th>RR</th>\n",
              "      <th>Temp</th>\n",
              "      <th>CVP</th>\n",
              "      <th>GCS</th>\n",
              "      <th>Vent</th>\n",
              "      <th>Time_CBC</th>\n",
              "      <th>WBC</th>\n",
              "      <th>Hgb</th>\n",
              "      <th>Hct</th>\n",
              "      <th>Platelet</th>\n",
              "      <th>Time Labs</th>\n",
              "      <th>Na</th>\n",
              "      <th>K_pos</th>\n",
              "      <th>BUN</th>\n",
              "      <th>Creatnine</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>Tbili</th>\n",
              "      <th>Chloride</th>\n",
              "      <th>V_CO2</th>\n",
              "      <th>PaO2</th>\n",
              "      <th>FIO2</th>\n",
              "      <th>PaCO2</th>\n",
              "      <th>HCO3</th>\n",
              "      <th>PH</th>\n",
              "      <th>Sepsis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21</td>\n",
              "      <td>2011-01-02</td>\n",
              "      <td>614.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>No</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.9</td>\n",
              "      <td>8.1</td>\n",
              "      <td>24.5</td>\n",
              "      <td>578.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.53</td>\n",
              "      <td>110.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>101.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21</td>\n",
              "      <td>2011-01-03</td>\n",
              "      <td>600.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>37.3</td>\n",
              "      <td>7.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>No</td>\n",
              "      <td>59.0</td>\n",
              "      <td>7.8</td>\n",
              "      <td>7.9</td>\n",
              "      <td>25.1</td>\n",
              "      <td>615.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>3.7</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.55</td>\n",
              "      <td>130.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>104.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21</td>\n",
              "      <td>2011-01-04</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>37.5</td>\n",
              "      <td>7.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>No</td>\n",
              "      <td>208.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>8.7</td>\n",
              "      <td>26.6</td>\n",
              "      <td>607.0</td>\n",
              "      <td>208.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.53</td>\n",
              "      <td>172.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>103.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21</td>\n",
              "      <td>2011-01-05</td>\n",
              "      <td>930.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>37.5</td>\n",
              "      <td>7.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>No</td>\n",
              "      <td>103.0</td>\n",
              "      <td>9.3</td>\n",
              "      <td>8.4</td>\n",
              "      <td>25.7</td>\n",
              "      <td>414.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>4.8</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.49</td>\n",
              "      <td>150.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>103.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.21</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21</td>\n",
              "      <td>2011-01-06</td>\n",
              "      <td>1130.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>No</td>\n",
              "      <td>130.0</td>\n",
              "      <td>8.4</td>\n",
              "      <td>8.9</td>\n",
              "      <td>27.7</td>\n",
              "      <td>701.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.51</td>\n",
              "      <td>109.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>103.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6536</th>\n",
              "      <td>PCR-004-00018</td>\n",
              "      <td>2013-05-27</td>\n",
              "      <td>600.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>38.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>211.0</td>\n",
              "      <td>17.6</td>\n",
              "      <td>9.2</td>\n",
              "      <td>26.8</td>\n",
              "      <td>454.0</td>\n",
              "      <td>211.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.88</td>\n",
              "      <td>139.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>103.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6537</th>\n",
              "      <td>PCR-004-00018</td>\n",
              "      <td>2013-05-28</td>\n",
              "      <td>600.0</td>\n",
              "      <td>158.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>37.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6538</th>\n",
              "      <td>PCR-004-00018</td>\n",
              "      <td>2013-05-29</td>\n",
              "      <td>600.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>38.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6539</th>\n",
              "      <td>PCR-004-00018</td>\n",
              "      <td>2013-05-30</td>\n",
              "      <td>600.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>38.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6540</th>\n",
              "      <td>PCR-004-00018</td>\n",
              "      <td>2013-05-31</td>\n",
              "      <td>600.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>38.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6541 rows × 32 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           PER_CODE Collection Date  Time Vitals  ...  HCO3   PH  Sepsis\n",
              "0                21      2011-01-02        614.0  ...   NaN  NaN       0\n",
              "1                21      2011-01-03        600.0  ...   NaN  NaN       0\n",
              "2                21      2011-01-04       1000.0  ...   NaN  NaN       0\n",
              "3                21      2011-01-05        930.0  ...   NaN  NaN       0\n",
              "4                21      2011-01-06       1130.0  ...   NaN  NaN       0\n",
              "...             ...             ...          ...  ...   ...  ...     ...\n",
              "6536  PCR-004-00018      2013-05-27        600.0  ...   NaN  NaN       0\n",
              "6537  PCR-004-00018      2013-05-28        600.0  ...   NaN  NaN       0\n",
              "6538  PCR-004-00018      2013-05-29        600.0  ...   NaN  NaN       0\n",
              "6539  PCR-004-00018      2013-05-30        600.0  ...   NaN  NaN       0\n",
              "6540  PCR-004-00018      2013-05-31        600.0  ...   NaN  NaN       0\n",
              "\n",
              "[6541 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dib_zUIG_2D-",
        "colab_type": "text"
      },
      "source": [
        "## Data Preprocessing ##\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Vh2nuez_teH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Drop_nan_row(df):\n",
        "  \n",
        "  drop_idx = []\n",
        "  for i in range(len(df)):\n",
        "    nan_count = 0\n",
        "    for x in df.loc[i]:\n",
        "      if str(x) == 'nan':\n",
        "        nan_count += 1\n",
        "    if nan_count >= 15:\n",
        "      drop_idx.append(i)\n",
        "    \n",
        "  modified_df = df.drop(df.index[drop_idx], errors = 'ignore')\n",
        "  modified_df = modified_df.reset_index(drop = True)\n",
        "\n",
        "  return modified_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07tBdERtAkMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Drop_unrelated_cols(df):\n",
        "  df = df.drop(columns = ['PER_CODE', 'Collection Date', 'Time Vitals', 'Time Labs', 'Time_CBC', 'Vent'], errors = 'ignore')\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AV5WZumAoZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Drop_nan_col(df):\n",
        "  \n",
        "  num_rows = len(df)\n",
        "  for x in df:\n",
        "    num_nan = 0\n",
        "    for i in df[x]:\n",
        "      if str(i) == 'nan':\n",
        "        num_nan += 1\n",
        "    \n",
        "    if (num_nan/num_rows) >= 0.2:\n",
        "      df = df.drop(columns = x, errors = 'ignore')\n",
        "  \n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LScRw4gWAt7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Complete_dataset(df):\n",
        "\n",
        "  # Change \"Yes\" and \"No\" under \"Vent\" to 1 and 0\n",
        "  df = df.replace('No', 0)\n",
        "  df = df.replace('Yes', 1)\n",
        "\n",
        "  # drop nan or replace them with other value\n",
        "  df = df.dropna()\n",
        "  df = df.reset_index(drop = True)\n",
        "\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h75yiEpAABp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_preprocess(df):\n",
        "\n",
        "  # drop rows that have too many nan\n",
        "  df = Drop_nan_row(df)\n",
        "  # drop times and patient ids\n",
        "  df = Drop_unrelated_cols(df)\n",
        "  # drop cols that have too many nan\n",
        "  df = Drop_nan_col(df)\n",
        "  # Replace all the other nans\n",
        "  df = Complete_dataset(df)\n",
        "\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypWsMIYjAwwx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bg = data_preprocess(bg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roPBfZ_UAyIB",
        "colab_type": "text"
      },
      "source": [
        "## Finding Score ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSbk_nS5A2xr",
        "colab_type": "code",
        "outputId": "61d21728-be3c-4031-9a69-23e0adba00f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "pip install -U imbalanced-learn"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting imbalanced-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/73/36a13185c2acff44d601dc6107b5347e075561a49e15ddd4e69988414c3e/imbalanced_learn-0.6.2-py3-none-any.whl (163kB)\n",
            "\r\u001b[K     |██                              | 10kB 18.0MB/s eta 0:00:01\r\u001b[K     |████                            | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 40kB 1.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 61kB 2.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 71kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 81kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 92kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 143kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 153kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 163kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.14.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.22 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.22.1)\n",
            "Installing collected packages: imbalanced-learn\n",
            "  Found existing installation: imbalanced-learn 0.4.3\n",
            "    Uninstalling imbalanced-learn-0.4.3:\n",
            "      Successfully uninstalled imbalanced-learn-0.4.3\n",
            "Successfully installed imbalanced-learn-0.6.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PS_iV-PcA6Ac",
        "colab_type": "code",
        "outputId": "b18a2ad6-9aad-4544-b2fe-1c860b543a49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import svm\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.feature_selection import RFE\n",
        "import imblearn"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHlMA0GJLGZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def Scores_calculation(train_x, train_y, test_x, test_y):\n",
        "#   precision_scores = [[],[]]\n",
        "#   recall_scores = [[],[]]\n",
        "#   f1_score_scores = [[],[]]\n",
        "\n",
        "#   model = RandomForestClassifier()\n",
        "#   for i in range(0,10):\n",
        "#     model.fit(train_x, train_y)\n",
        "#     predictions = model.predict(test_x)\n",
        "#     report = classification_report(test_y, predictions, output_dict = True)\n",
        "\n",
        "#     precision_scores[0].append(report['0']['precision'])\n",
        "#     recall_scores[0].append(report['0']['recall'])\n",
        "#     f1_score_scores[0].append(report['0']['f1-score'])\n",
        "    \n",
        "#     precision_scores[1].append(report['1']['precision'])\n",
        "#     recall_scores[1].append(report['1']['recall'])\n",
        "#     f1_score_scores[1].append(report['1']['f1-score'])\n",
        "\n",
        "#   precision_scores_avg_0 = sum(precision_scores[0]) / 10\n",
        "#   recall_scores_avg_0 = sum(recall_scores[0]) / 10\n",
        "#   f1_score_scores_avg_0 = sum(f1_score_scores[0]) / 10\n",
        "\n",
        "#   precision_scores_avg_1 = sum(precision_scores[1]) / 10\n",
        "#   recall_scores_avg_1 = sum(recall_scores[1]) / 10\n",
        "#   f1_score_scores_avg_1 = sum(f1_score_scores[1]) / 10\n",
        "\n",
        "#   # print('0 precision average', precision_scores_avg_0)\n",
        "#   # print('1 precision average', precision_scores_avg_1)\n",
        "#   # print('0 recall average', recall_scores_avg_0)\n",
        "#   # print('1 recall average', recall_scores_avg_1)\n",
        "#   # print('0 f1_socre average', f1_score_scores_avg_0)\n",
        "#   # print('1 f1_socre average', f1_score_scores_avg_1)\n",
        "#   # print('average f1_scores', (f1_score_scores_avg_0 + f1_score_scores_avg_1)/2)\n",
        "\n",
        "#   return (f1_score_scores_avg_0 + f1_score_scores_avg_1)/2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3qPm9yuRsdS",
        "colab_type": "text"
      },
      "source": [
        "## Getting Best Features ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkCz1NvJlgOd",
        "colab_type": "text"
      },
      "source": [
        "### Progressive Selection ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "viMlbAZ2QvL8",
        "colab": {}
      },
      "source": [
        "# model = RandomForestClassifier()\n",
        "# x = bg[['Hct', 'Platelet', 'WBC', 'Glucose']].values\n",
        "# y = bg['Sepsis'].values\n",
        "# train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# scaler = RobustScaler()\n",
        "# train_x = scaler.fit_transform(train_x)\n",
        "# test_x = scaler.transform(test_x)\n",
        "\n",
        "# n_minority = len(train_y[train_y == 1])\n",
        "# n_majority = int(n_minority * 2.5)\n",
        "# sampling_numbers = {0: n_majority, 1: n_minority}\n",
        "\n",
        "# rus = imblearn.under_sampling.RandomUnderSampler(sampling_strategy=sampling_numbers)\n",
        "# train_x_rus, train_y_rus = rus.fit_resample(train_x, train_y)\n",
        "# train_y_rus = pd.Series(train_y_rus)\n",
        "  \n",
        "# score = Scores_calculation(train_x_rus, train_y_rus, test_x, test_y)\n",
        "# print(score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9qrPzKWdIto",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = RandomForestClassifier()\n",
        "# temp = list(bg.columns)\n",
        "# temp.remove('Hct')\n",
        "# temp.remove('Platelet')\n",
        "# temp.remove('WBC')\n",
        "# temp.remove('Sepsis')\n",
        "# temp.remove('Temp')\n",
        "# temp.remove('RR')\n",
        "# temp.remove('HR')\n",
        "# col_use = ['Hct', 'Platelet', 'WBC', 'Temp', 'RR', 'HR']\n",
        "\n",
        "# for f in temp:\n",
        "#   g = [f]\n",
        "#   g = col_use + g\n",
        "\n",
        "#   x = bg[g].values\n",
        "#   y = bg['Sepsis'].values\n",
        "#   train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=0)\n",
        "\n",
        "#   scaler = RobustScaler()\n",
        "#   train_x = scaler.fit_transform(train_x)\n",
        "#   test_x = scaler.transform(test_x)\n",
        "\n",
        "#   n_minority = len(train_y[train_y == 1])\n",
        "#   n_majority = int(n_minority * 2.5)\n",
        "#   sampling_numbers = {0: n_majority, 1: n_minority}\n",
        "\n",
        "#   rus = imblearn.under_sampling.RandomUnderSampler(sampling_strategy=sampling_numbers)\n",
        "#   train_x_rus, train_y_rus = rus.fit_resample(train_x, train_y)\n",
        "#   train_y_rus = pd.Series(train_y_rus)\n",
        "  \n",
        "#   score = Scores_calculation(train_x_rus, train_y_rus, test_x, test_y)\n",
        "#   print(g,':',score)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuJxAe5aldKd",
        "colab_type": "text"
      },
      "source": [
        "Best feature combination: ['Hct', 'Platelet', 'WBC', 'Temp', 'RR', 'HR']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUXgJR7ilt0P",
        "colab_type": "text"
      },
      "source": [
        "### Regressive Selection ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsjxABy-lx8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.feature_selection import RFE\n",
        "\n",
        "# col = list(bg.columns)\n",
        "# col.remove('Sepsis')\n",
        "# x = bg[col].values\n",
        "# y = bg['Sepsis'].values\n",
        "# train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# scaler = RobustScaler()\n",
        "# train_x = scaler.fit_transform(train_x)\n",
        "# test_x = scaler.transform(test_x)\n",
        "\n",
        "# n_minority = len(train_y[train_y == 1])\n",
        "# n_majority = int(n_minority * 2.5)\n",
        "# sampling_numbers = {0: n_majority, 1: n_minority}\n",
        "\n",
        "# rus = imblearn.under_sampling.RandomUnderSampler(sampling_strategy=sampling_numbers)\n",
        "# train_x_rus, train_y_rus = rus.fit_resample(train_x, train_y)\n",
        "# train_y_rus = pd.Series(train_y_rus)\n",
        "\n",
        "# estimator = RandomForestClassifier()\n",
        "# selector = RFE(estimator, 3, step=1)\n",
        "# selector = selector.fit(train_x_rus, train_y_rus)\n",
        "\n",
        "# new_train_x = train_x[:, selector.support_]\n",
        "# new_test_x = test_x[:, selector.support_]\n",
        "\n",
        "# model = RandomForestClassifier()\n",
        "\n",
        "# f1_score_scores = [[],[]]\n",
        "\n",
        "# model = RandomForestClassifier()\n",
        "# for i in range(0,10):\n",
        "#   model.fit(new_train_x, train_y)\n",
        "#   predictions = model.predict(new_test_x)\n",
        "#   report = classification_report(test_y, predictions, output_dict = True)\n",
        "\n",
        "#   f1_score_scores[0].append(report['0']['f1-score'])\n",
        "#   f1_score_scores[1].append(report['1']['f1-score'])\n",
        "#   f1_score_scores_avg_0 = sum(f1_score_scores[0]) / 10\n",
        "#   f1_score_scores_avg_1 = sum(f1_score_scores[1]) / 10\n",
        "\n",
        "# print((f1_score_scores_avg_0 + f1_score_scores_avg_1)/2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vYmAFDP5wzC",
        "colab_type": "text"
      },
      "source": [
        "3 features: f1_score = 0.5483979297526201 \\\\\n",
        "4 features: f1_score = 0.5807557454179925 \\\\\n",
        "5 features: f1_score = 0.5788802053854059 \\\\\n",
        "6 features: f1_score = 0.5769307206585933 \\\\\n",
        "7 features: f1_score = 0.5722500953954065"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSgkYfshB9IU",
        "colab_type": "text"
      },
      "source": [
        "## Best features + SVM + RFE ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tn0VP_1B2RqL",
        "colab_type": "code",
        "outputId": "1e4ae4e4-913c-4121-dd7d-5cdbbd3b543f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "x = bg[['Hct', 'Platelet', 'WBC', 'Temp', 'RR', 'HR']].values\n",
        "y = bg['Sepsis'].values\n",
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=0)\n",
        "\n",
        "scaler = RobustScaler()\n",
        "train_x = scaler.fit_transform(train_x)\n",
        "test_x = scaler.transform(test_x)\n",
        "\n",
        "n_minority = len(train_y[train_y == 1])\n",
        "n_majority = int(n_minority * 2.5)\n",
        "sampling_numbers = {0: n_majority, 1: n_minority}\n",
        "\n",
        "rus = imblearn.under_sampling.RandomUnderSampler(sampling_strategy=sampling_numbers)\n",
        "train_x_rus, train_y_rus = rus.fit_resample(train_x, train_y)\n",
        "train_y_rus = pd.Series(train_y_rus)\n",
        "\n",
        "f1_score_scores = [[],[]]\n",
        "sensitivity = []\n",
        "specificity = []\n",
        "\n",
        "# RFE: Feature ranking with recursive feature elimination.\n",
        "# SVM is a classifier -> predicting discrete categorical labels\n",
        "# SVR, which stands for Support Vector Regressor, is a regressor\n",
        "# SVR for continuous data, SVC for discrete data\n",
        "# SVM for discrete\n",
        "estimator = svm.SVC(kernel=\"linear\", probability=True)\n",
        "model = RFE(estimator, 5, step=1)\n",
        "\n",
        "for i in range(0,10):\n",
        "  model.fit(train_x_rus, train_y_rus)\n",
        "  predictions = model.predict(test_x)\n",
        "  report = classification_report(test_y, predictions, output_dict = True)\n",
        "  ss = imblearn.metrics.sensitivity_specificity_support(test_y, predictions, average='macro')\n",
        "  \n",
        "  sensitivity.append(ss[0])\n",
        "  specificity.append(ss[1])\n",
        "\n",
        "  f1_score_scores[0].append(report['0']['f1-score'])\n",
        "  f1_score_scores[1].append(report['1']['f1-score'])\n",
        "\n",
        "f1_score_scores_avg_0 = sum(f1_score_scores[0]) / 10\n",
        "f1_score_scores_avg_1 = sum(f1_score_scores[1]) / 10\n",
        "sensitivity_avg = sum(sensitivity) / 10\n",
        "specificity_avg = sum(specificity) / 10\n",
        "\n",
        "print(\"f1 score = \", (f1_score_scores_avg_0 + f1_score_scores_avg_1)/2)\n",
        "print(\"sensitivity = \", sensitivity_avg)\n",
        "print(\"specificity = \", specificity_avg)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1 score =  0.45563674321503134\n",
            "sensitivity =  0.5\n",
            "specificity =  0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7ed8a8b3-454c-42f4-9c44-847e1df65113",
        "id": "X4qvESaAZ-JL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "y_score = model.predict_proba(test_x)[:,1]\n",
        "false_positive_rate, true_positive_rate, threshold = roc_curve(test_y, y_score)\n",
        "print('roc_auc_score = ', roc_auc_score(test_y, y_score))\n",
        "\n",
        "plt.title('ROC Curve')\n",
        "plt.plot(false_positive_rate, true_positive_rate)\n",
        "plt.plot([0, 1], ls=\"--\")\n",
        "plt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "roc_auc_score =  0.6124351458796577\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}